### Project AI Systems: Technical Overview

**Core Philosophy: AI-Powered Marketing Content Generation Platform**

This platform leverages cutting-edge AI models to process multimedia assets and generate targeted marketing content through a structured pipeline of asset processing, transcription, and text generation.

**I. Asset Processing Service Architecture:**

*   **Supported Asset Types:** The system accepts video, audio, and text document uploads through the platform interface.
*   **Media Processing Dependencies:** The `asset-processing-service` includes **`ffmpeg-python`** in its dependencies (see `pyproject.toml`), which provides capabilities for handling video and audio file manipulation. This allows the service to extract audio streams from video files for transcription.
*   **Asynchronous Processing:** The asset processing runs as a separate Python service that communicates with the main Next.js application via API endpoints, handling jobs asynchronously with configurable worker pools (`MAX_NUM_WORKERS`).

**II. Transcription Engine (Whisper-1 Implementation):**

*   **Transcription Model:** The system uses OpenAI's **Whisper-1 model** for automatic speech recognition, as configured in `asset_processing_service/config.py` (`OPENAI_MODEL = "whisper-1"`).
*   **How Whisper-1 Works:** Whisper is a Transformer-based model that:
    1.  Converts audio into a visual representation (spectrogram)
    2.  Uses an encoder to understand the audio patterns
    3.  Uses a decoder to generate the corresponding text transcript
    *   It handles multiple languages and includes automatic punctuation
*   **Integration:** The transcribed text is stored in the database as asset `content` with corresponding `tokenCount` tracking.

**III. Content Storage and Management:**

*   **Database Schema:** Assets and their transcribed content are stored in PostgreSQL tables:
    *   `assetsTable`: Stores file metadata, transcribed `content`, and `tokenCount`
    *   `promptsTable`: Stores user-created prompts with their own `tokenCount`
    *   `generatedContentTable`: Stores the AI-generated marketing content
*   **Simple Content Aggregation:** When generating content, the system concatenates all asset content into a single context string:
    ```typescript
    const contentFromAssets = assets.map((asset) => asset.content).join("\n\n");
    ```

**IV. Content Generation Pipeline:**

*   **Prompt Management:** Users can:
    *   Create custom prompts through the UI (`ConfigurePromptsStep.tsx`)
    *   Import pre-built prompt templates (`templatePromptsTable`)
    *   Use example prompts from the `resources` directory (e.g., `linkedin-launch-prompt.md`)
*   **Generation Process:**
    1.  User selects or creates prompts for their project
    2.  System combines all asset content into a summary
    3.  For each prompt, the system sends a request to OpenAI's API:
        ```typescript
        prompt: `
        Use the following prompt and summary to generate new content:
        ** PROMPT:
        ${prompt.prompt}
        ---------------------
        ** SUMMARY:
        ${contentFromAssets}
        `
        ```
    4.  The LLM generates marketing content based on the prompt and asset context
*   **Model Selection & Fallback:** The system attempts to use GPT-4o first, with automatic fallback to GPT-4o-mini if the primary model is unavailable (handles 503/429 errors).
*   **Token Management:** 
    *   Uses `tiktoken` library for accurate token counting
    *   Enforces limits: `MAX_TOKENS_PROMPT = 20000` and `MAX_TOKENS_ASSETS`
    *   Pre-validates token counts before sending requests to avoid API errors

**V. Output Management and Persistence:**

*   **Generated Content Storage:** All AI-generated content is stored in the `generatedContentTable` with:
    *   Link to the source project (`projectId`)
    *   The prompt name that generated it
    *   The full generated text result
    *   Order field for organizing multiple outputs
*   **User Interface:** The `GenerateContentStep.tsx` component provides real-time feedback on generation progress and displays results.

**VI. Actual AI Capabilities Summary:**

The platform currently implements:
*   **Whisper-1 ASR** for audio/video transcription
*   **GPT-4o/GPT-4o-mini** for text generation
*   **Token counting** with tiktoken for cost and limit management
*   **Prompt templates** for reusable content strategies
*   **Resilient API handling** with model fallback
*   **Asynchronous processing** for handling large media files

The system follows a straightforward pipeline: Upload → Transcribe → Store → Generate, with the AI models serving as powerful tools within this structured workflow rather than autonomous agents making independent decisions. 
